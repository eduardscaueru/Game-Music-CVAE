1. Modelul face overfit pe blade runner cu F1 de 0.93 dupa vreo 500 epoci cu urmatoarea configuratie:
ENCODER_UNITS = 128
ENCODER_UNITS_2 = 64
# ENCODER_UNITS_3 = 512
LATENT_DIM = 32
BARS = 0.5
BATCH_SIZE = 4
FS = 16
NUM_INSTRUMENTS = 1
MAX_INSTRUMENTS_PER_SONG = 2
+ Layer normalization

2. F1 de >93 dupa 2000 epoci pe tot dataset ul fara horror si fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 350
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 256
LATENT_DIM = 128
BETA = 0.01
EPOCHS = 15001
BARS = 0.5
BATCH_SIZE = 32
FS = 8
NUM_INSTRUMENTS = 8
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

3. F1 de >99 dupa 1600 epoci pe tot dataset ul fara horror si fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 350
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 256
LATENT_DIM = 128
BETA = 0.01
EPOCHS = 2501
BARS = 0.5
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 8
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

4. F1 de >96 dupa 1000 epoci pe tot dataset ul fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 256
LATENT_DIM = 128
BETA = 0.01
EPOCHS = 2501
BARS = 0.5
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

5. F1 de >96 dupa 1800 epoci pe tot dataset ul fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 256
LATENT_DIM = 128
BETA = 0.01
EPOCHS = 2501
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

6. F1 de >... dupa ... epoci pe tot dataset ul fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 256
LATENT_DIM = 128
BETA = 5.25 (tot nu converge dar cica trebuie ca BETA sa fie N/M (https://qr.ae/pyFFxM) (0.1 converge greu)
Daca beta nu exista atunci modelul cica va invata o melodie/output pentru toate exemplele din spatiul latent. Dar aici (https://stackoverflow.com/questions/71692032/vae-reconstruction-loss-mse-not-decreasing-but-kl-divergence-is) zice ca BETA e 1 si poate fi si mai mic dar atunci nu mai poti avea disentangled latent space.
EPOCHS = 6001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

7. F1 de >80 dupa 1700 epoci, dar dupa a inceput sa scada pana la 40, iar apoi sa urce pana la 65 la sfarsit pe tot dataset ul (kung_fu in loc de doom) fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = 0.01
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
optimizer = keras.optimizers.Adam()

8. F1 de >96 dupa 1600 epoci pe tot dataset ul (kung_fu in loc de doom) fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = 0.01
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

9. F1 de >... dupa ... epoci pe tot dataset ul (kung_fu in loc de doom) fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = frange_cycle_sigmoid
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

10. F1 de >... dupa ... epoci pe tot dataset ul (kung_fu in loc de doom) fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = frange_cycle_cosine
EPOCHS = 4001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

11. F1 de >96 dupa 2500 epoci pe tot dataset ul (kung_fu in loc de doom) fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = frange_cycle_cosine
EPOCHS = 4001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 14
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)


12. F1 de >45 dupa 3000 epoci pe tot dataset ul fara indiana jones cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 256
LATENT_DIM = 128
BETA = 0.01
EPOCHS = 3001
BARS = 2
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 10
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

13. F1 de >94 dupa 2400 epoci pe tot dataset ul nou cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = 0.01
EPOCHS = 3001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 13
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

14. F1 de >.. dupa ... epoci pe tot dataset ul nou cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = frange_cycle_sigmoid
EPOCHS = 4001	
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 13
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

15. F1 de >25 dupa 3001 epoci pe tot dataset ul nou cu urmatoarea configuratie:
ENCODER_UNITS = 512
ENCODER_UNITS_2 = 256
ENCODER_UNITS_3 = 128
LATENT_DIM = 64
BETA = 5.25 (1.86 (beta_norm) tot la fel)
EPOCHS = 3001
BARS = 1
BATCH_SIZE = 32
FS = 16
NUM_INSTRUMENTS = 13
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)

17. F1 de >75 (de rulat cu mai multe epoci) dupa 4000 epoci pe urmatorul dataset augmentat cu urmatoarea configuratie:
[256, 128, 64]
LATENT_DIM = 32
BETA = 1
EPOCHS = 4000
BARS = 1
BATCH_SIZE = 64
FS = 16
NUM_INSTRUMENTS = 5
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action/kung_fu',
        'data/action/metroid2',
        'data/action/r-type'
    ],
    [
        'data/adventure/blade_runner',
        'data/adventure/castlevania2'
        # 'data/adventure/myst'
    ],
    [
        'data/arcade/blox',
        'data/arcade/burning_monkey'
        # 'data/arcade/mario'
    ]
    # [
    #     'data/horror/blood',
    #     'data/horror/house_of_the_dead'
    # ]
]

18. F1 de >96 dupa 4000 epoci pe urmatorul dataset augumentat cu urmatoarea configuratie:
[256, 128, 64]
LATENT_DIM = 32
BETA = cosine
EPOCHS = 4000
BARS = 1
BATCH_SIZE = 64
FS = 16
NUM_INSTRUMENTS = 5
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action/kung_fu',
        'data/action/metroid2',
        'data/action/r-type'
    ],
    [
        'data/adventure/blade_runner',
        'data/adventure/castlevania2'
        # 'data/adventure/myst'
    ],
    [
        'data/arcade/blox',
        'data/arcade/burning_monkey'
        # 'data/arcade/mario'
    ]
    # [
    #     'data/horror/blood',
    #     'data/horror/house_of_the_dead'
    # ]
]

20. F1 de >60 dupa 2000 epoci pe urmatorul dataset augumentat cu urmatoarea configuratie: (spatiu latent cu forme ca SVM (par separabile in spatiu mai mare)
[256, 256, 128, 128]
LATENT_DIM = 64
BETA = 0.5
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 128
FS = 8
NUM_INSTRUMENTS = 5
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action/kung_fu',
        'data/action/metroid2',
        'data/action/r-type'
    ],
    [
        'data/adventure/blade_runner',
        'data/adventure/castlevania2'
        # 'data/adventure/myst'
    ],
    [
        'data/arcade/blox',
        'data/arcade/burning_monkey'
        # 'data/arcade/mario'
    ]
]


21: F1 de >60 dupa 2000 epoci pe urmatorul dataset augumentat cu urmatoarea configuratie:
256, 128, 128
LATENT_DIM = 64
BETA = 0.3 si 0.7 pentru MSE (https://medium.com/@outerrencedl/variational-autoencoder-and-a-bit-kl-divergence-with-pytorch-ce04fd55d0d7)
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 64
FS = 16
NUM_INSTRUMENTS = 6
MAX_INSTRUMENTS_PER_SONG = 1
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action'
        # 'data/action/kung_fu',
        # 'data/action/metroid2',
        # 'data/action/r-type'
    ],
    [
        'data/adventure'
        # 'data/adventure/blade_runner',
        # 'data/adventure/castlevania2'
        # 'data/adventure/myst'
    ],
    [
        'data/arcade'
        # 'data/arcade/blox',
        # 'data/arcade/burning_monkey'
        # 'data/arcade/mario'
    ],
    [
        'data/horror'
        # 'data/horror/blood',
        # 'data/horror/house_of_the_dead'
    ]
]
Similarity
generated_action_21_greedy vs Met_II = 0.5015625
generated_action_21_greedy vs STANLevel_Intro = 0.49639205
generated_action_21_greedy vs T_kungfu = 0.50326705
generated_action_21_greedy vs r-type4 = 0.50139205
generated_action_21_greedy vs r-typeL6 = 0.49903409

22.1: F1 de >37 dupa 1000 epoci pe urmatorul dataset augmentat cu urmatoarea configuratie:
256, 128, 128
LATENT_DIM = 64
BETA = 1.0 nu minimizeaza kl
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 64
FS = 16
NUM_INSTRUMENTS = 5
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action'
        # 'data/action/kung_fu',
        # 'data/action/metroid2',
        # 'data/action/r-type'
    ],
    [
        'data/adventure'
        # 'data/adventure/blade_runner',
        # 'data/adventure/castlevania2'
    ],
    [
        'data/arcade'
        # 'data/arcade/blox',
        # 'data/arcade/burning_monkey'
    ]
]
rank order
['/home/ediuso/Documents/Licenta/Game-Music-CVAE/out/generated_arcade_15_greedy.mid'
 '/home/ediuso/Documents/Licenta/Game-Music-CVAE/out/generated_arcade_21_greedy.mid'
 '/home/ediuso/Documents/Licenta/Game-Music-CVAE/out/generated_arcade_changelog_13_greedy.mid']

22.2: F1 de >... dupa ... epoci pe urmatorul dataset augmentat cu urmatoarea configuratie:
256, 128, 128
LATENT_DIM = 64
BETA = cosine [0,1]
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 64
FS = 16
NUM_INSTRUMENTS = 5
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action'
        # 'data/action/kung_fu',
        # 'data/action/metroid2',
        # 'data/action/r-type'
    ],
    [
        'data/adventure'
        # 'data/adventure/blade_runner',
        # 'data/adventure/castlevania2'
    ],
    [
        'data/arcade'
        # 'data/arcade/blox',
        # 'data/arcade/burning_monkey'
    ]
]

23: F1 de >... dupa ... epoci pe urmatorul dataset augmentat cu urmatoarea configuratie:
256, 128, 128
LATENT_DIM = 64
BETA = cosine [0.5,1.5]
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 64
FS = 16
NUM_INSTRUMENTS = 5
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action'
        # 'data/action/kung_fu',
        # 'data/action/metroid2',
        # 'data/action/r-type'
    ],
    [
        'data/adventure'
        # 'data/adventure/blade_runner',
        # 'data/adventure/castlevania2'
    ],
    [
        'data/arcade'
        # 'data/arcade/blox',
        # 'data/arcade/burning_monkey'
    ]
]

24: F1 de >... dupa ... epoci pe urmatorul dataset extins la durata originala a melodiilor augmentat cu urmatoarea configuratie:
256, 128, 128
LATENT_DIM = 64
BETA = 10.0
EPOCHS = 2001
BARS = 1
BATCH_SIZE = 128
FS = 16
NUM_INSTRUMENTS = 4
MAX_INSTRUMENTS_PER_SONG = 2
MAX_INSTRUMENTS_GENERATED = 3
lr = 1.0
optimizer = keras.optimizers.Adadelta(learning_rate=lr)
metroid + burning_moneky genereaza bass nou spre exemplu
styles = [
    [
        'data/action'
        # 'data/action/kung_fu',
        # 'data/action/metroid2',
        # 'data/action/r-type'
    ],
    [
        'data/adventure'
        # 'data/adventure/blade_runner',
        # 'data/adventure/castlevania2'
    ],
    [
        'data/arcade'
        # 'data/arcade/blox',
        # 'data/arcade/burning_monkey'
    ]
]


Am incercat interpolare intre metroid si r-type pentru changelog 22 deoarece pe grafic erau apropiate clusterele.
Interpolarea cu step ul 0 similaritate (ar trebui sa fie metroid): 0.5104545454545457 /home/ediuso/Documents/Licenta/Game-Music-CVAE/data/action/metroid2/STANLevel_Intro_-1.mid
Interpolarea cu step ul 4, ultimul, similaritate (ar trebui sa fie r-type): 0.5140909090909095 /home/ediuso/Documents/Licenta/Game-Music-CVAE/data/action/r-type/r-typeL6_-1.mid



